{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b79459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9475c96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0=[[-0.50328585 -1.1382643 ]\n",
      " [-0.35231146  0.52302986]\n",
      " [-1.23415337 -1.23413696]\n",
      " [ 0.57921282 -0.23256527]\n",
      " [-1.46947439 -0.45743996]\n",
      " [-1.46341769 -1.46572975]\n",
      " [-0.75803773 -2.91328024]\n",
      " [-2.72491783 -1.56228753]\n",
      " [-2.01283112 -0.68575267]\n",
      " [-1.90802408 -2.4123037 ]]\n",
      "y0=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "X1=[[ 2.46564877  0.7742237 ]\n",
      " [ 1.0675282  -0.42474819]\n",
      " [ 0.45561728  1.11092259]\n",
      " [-0.15099358  1.37569802]\n",
      " [ 0.39936131  0.70830625]\n",
      " [ 0.39829339  2.85227818]\n",
      " [ 0.98650278 -0.05771093]\n",
      " [ 1.82254491 -0.22084365]\n",
      " [ 1.2088636  -0.95967012]\n",
      " [-0.32818605  1.19686124]]\n",
      "y1=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data\n",
    "num_samples = 10\n",
    "mean0 = np.array([-1, -1])\n",
    "mean1 = np.array([1, 1])\n",
    "cov = np.eye(2)          # 2x2 Identity matrix\n",
    "\n",
    "X0 = np.random.multivariate_normal(mean0, cov, num_samples)\n",
    "X1 = np.random.multivariate_normal(mean1, cov, num_samples)\n",
    "y0 = np.zeros(num_samples)\n",
    "y1 = np.ones(num_samples)\n",
    "\n",
    "print(f'X0={X0}\\ny0={y0}\\nX1={X1}\\ny1={y1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5960fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train= [[-0.50328585 -1.1382643 ]\n",
      " [-0.35231146  0.52302986]\n",
      " [-1.23415337 -1.23413696]\n",
      " [ 0.57921282 -0.23256527]\n",
      " [-1.46947439 -0.45743996]\n",
      " [ 2.46564877  0.7742237 ]\n",
      " [ 1.0675282  -0.42474819]\n",
      " [ 0.45561728  1.11092259]\n",
      " [-0.15099358  1.37569802]\n",
      " [ 0.39936131  0.70830625]]\n",
      "y_train= [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "x_test= [[-1.46341769 -1.46572975]\n",
      " [-0.75803773 -2.91328024]\n",
      " [-2.72491783 -1.56228753]\n",
      " [-2.01283112 -0.68575267]\n",
      " [-1.90802408 -2.4123037 ]\n",
      " [ 0.39829339  2.85227818]\n",
      " [ 0.98650278 -0.05771093]\n",
      " [ 1.82254491 -0.22084365]\n",
      " [ 1.2088636  -0.95967012]\n",
      " [-0.32818605  1.19686124]]\n",
      "y_test= [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#getting the train and test set\n",
    "x_train = np.vstack((X0[:5], X1[:5]))\n",
    "y_train = np.hstack((y0[:5], y1[:5]))\n",
    "x_test = np.vstack((X0[5:], X1[5:]))\n",
    "y_test = np.hstack((y0[5:], y1[5:]))\n",
    "print(\"x_train=\", x_train)\n",
    "print(\"y_train=\", y_train)\n",
    "print(\"x_test=\", x_test)\n",
    "print(\"y_test=\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcfdb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.1320\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters randomly\n",
    "w1 = np.random.randn(2, 1)\n",
    "b1 = np.random.randn(1)\n",
    "w2 = np.random.randn(1, 1)\n",
    "b2 = np.random.randn(1)\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Training hyperparameters\n",
    "lr = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    z1 = X_train.dot(w1) + b1        # Hidden layer linear\n",
    "    a1 = sigmoid(z1)                 # Hidden layer activation\n",
    "    z2 = a1.dot(w2) + b2             # Output layer (no activation)\n",
    "    y_pred = z2.flatten()\n",
    "    \n",
    "    # Compute loss (MSE)\n",
    "    loss = np.mean((y_pred - y_train)**2)\n",
    "    \n",
    "    # Backward pass\n",
    "    N = X_train.shape[0]\n",
    "    dL_dy = 2 * (y_pred - y_train) / N                   # dL/dy_pred\n",
    "    \n",
    "    # Gradients for output layer\n",
    "    dW2 = a1.T.dot(dL_dy.reshape(-1, 1))                 # shape (1,1)\n",
    "    dB2 = np.sum(dL_dy)                                  # shape ()\n",
    "    \n",
    "    # Gradients for hidden layer\n",
    "    dA1 = dL_dy.reshape(-1, 1).dot(w2.T)                 # shape (N,1)\n",
    "    dZ1 = dA1 * a1 * (1 - a1)                            # shape (N,1)\n",
    "    dW1 = X_train.T.dot(dZ1)                             # shape (2,1)\n",
    "    dB1 = np.sum(dZ1, axis=0)                            # shape (1,)\n",
    "    \n",
    "    # Gradient descent update\n",
    "    w2 -= lr * dW2\n",
    "    b2 -= lr * dB2\n",
    "    w1 -= lr * dW1\n",
    "    b1 -= lr * dB1\n",
    "\n",
    "# Evaluate on test set\n",
    "z1_test = X_test.dot(w1) + b1\n",
    "a1_test = sigmoid(z1_test)\n",
    "z2_test = a1_test.dot(w2) + b2\n",
    "y_test_pred = z2_test.flatten()\n",
    "\n",
    "# Compute test MSE\n",
    "test_mse = np.mean((y_test_pred - y_test)**2)\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
